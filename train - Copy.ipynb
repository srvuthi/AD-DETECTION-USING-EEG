{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21e24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41fb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate YOUR dataset statistics instead of using pretrained ones\n",
    "def calculate_dataset_stats(samples):\n",
    "    \"\"\"Calculate mean and std from your actual dataset\"\"\"\n",
    "    all_eeg = []\n",
    "    all_ages = []\n",
    "\n",
    "    for path, age, label in samples[:100]:  # Sample 100 files for stats\n",
    "        try:\n",
    "            raw = np.loadtxt(path, delimiter=\",\", skiprows=1)\n",
    "            eeg = raw[:, :20].T  # Only EEG channels\n",
    "            # Basic filtering first\n",
    "            eeg = np.array([bandpass_filter(ch) for ch in eeg])\n",
    "            all_eeg.append(eeg.flatten())\n",
    "            all_ages.append(age)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    eeg_data = np.concatenate(all_eeg)\n",
    "    age_data = np.array(all_ages)\n",
    "\n",
    "    return {\n",
    "        'eeg_mean': np.mean(eeg_data),\n",
    "        'eeg_std': np.std(eeg_data),\n",
    "        'age_mean': np.mean(age_data),\n",
    "        'age_std': np.std(age_data)\n",
    "    }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "csv_dir = \"data/balanced_subset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc69cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, lowcut=1.0, highcut=40.0, fs=250.0, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def preprocess_eeg(file_path, target_length=500, stats=None):\n",
    "    raw = np.loadtxt(file_path, delimiter=\",\", skiprows=1)\n",
    "    eeg = raw[:, :22].T  # [22, T]\n",
    "\n",
    "    # Bandpass filter all 22 channels\n",
    "    eeg = np.array([bandpass_filter(ch) for ch in eeg])\n",
    "\n",
    "    # Truncate or pad to target length\n",
    "    if eeg.shape[1] > target_length:\n",
    "        eeg = eeg[:, :target_length]\n",
    "    else:\n",
    "        eeg = np.pad(eeg, ((0, 0), (0, target_length - eeg.shape[1])), mode=\"constant\")\n",
    "\n",
    "    # Use your dataset statistics for normalization\n",
    "    if stats:\n",
    "        eeg[:20] = (eeg[:20] - stats['eeg_mean']) / (stats['eeg_std'] + 1e-8)\n",
    "\n",
    "    return torch.tensor(eeg, dtype=torch.float32)\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, samples, stats=None):\n",
    "        self.samples = samples\n",
    "        self.stats = stats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, age, label = self.samples[idx]\n",
    "        eeg_tensor = preprocess_eeg(path, stats=self.stats)\n",
    "\n",
    "        # Normalize age with your dataset stats\n",
    "        if self.stats:\n",
    "            age_tensor = torch.tensor((age - self.stats['age_mean']) / self.stats['age_std'], dtype=torch.float32)\n",
    "        else:\n",
    "            age_tensor = torch.tensor(age / 100.0, dtype=torch.float32)  # Simple normalization\n",
    "\n",
    "        return eeg_tensor, age_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7e83bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 690\n",
      "Class distribution: [230 230 230]\n",
      "Train samples: 552\n",
      "Test samples: 138\n"
     ]
    }
   ],
   "source": [
    "# ====================== Data Loading with Proper Split ======================\n",
    "eeg_dir = \"data/balanced_subset\"\n",
    "annotation_path = \"data/annotation.json\"\n",
    "\n",
    "# Parse annotation\n",
    "with open(annotation_path) as f:\n",
    "    annotation = json.load(f)\n",
    "\n",
    "serial_to_label = {}\n",
    "serial_to_age = {}\n",
    "for entry in annotation[\"data\"]:\n",
    "    serial = entry[\"serial\"]\n",
    "    age = entry[\"age\"]\n",
    "    symptoms = [s.lower() for s in entry.get(\"symptom\", [])]\n",
    "    if \"ad\" in symptoms:\n",
    "        label = 2\n",
    "    elif \"mci\" in symptoms:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    serial_to_label[serial] = label\n",
    "    serial_to_age[serial] = age\n",
    "\n",
    "# Match to CSV files\n",
    "samples = []\n",
    "for fname in os.listdir(eeg_dir):\n",
    "    if fname.endswith(\".csv\"):\n",
    "        serial = fname.split('_')[1].split('.')[0]\n",
    "        if serial in serial_to_label and serial in serial_to_age:\n",
    "            path = os.path.join(eeg_dir, fname)\n",
    "            samples.append((path, serial_to_age[serial], serial_to_label[serial]))\n",
    "\n",
    "print(f\"Total samples: {len(samples)}\")\n",
    "labels = [s[2] for s in samples]\n",
    "print(f\"Class distribution: {np.bincount(labels)}\")\n",
    "\n",
    "\n",
    "# FIXED: Proper train/test split\n",
    "train_samples, test_samples = train_test_split(\n",
    "    samples, test_size=0.2, random_state=42,\n",
    "    stratify=labels  # Ensure balanced split\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_samples)}\")\n",
    "print(f\"Test samples: {len(test_samples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922581a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset statistics...\n",
      "Dataset stats: {'eeg_mean': np.float64(1.0273376978349166e-10), 'eeg_std': np.float64(2.715497684820624e-05), 'age_mean': np.float64(72.2), 'age_std': np.float64(9.67987603226405)}\n"
     ]
    }
   ],
   "source": [
    "# Calculate dataset statistics\n",
    "print(\"Calculating dataset statistics...\")\n",
    "stats = calculate_dataset_stats(train_samples)\n",
    "print(f\"Dataset stats: {stats}\")\n",
    "\n",
    "# Create datasets with proper stats\n",
    "train_dataset = EEGDataset(train_samples, stats=stats)\n",
    "test_dataset = EEGDataset(test_samples, stats=stats)\n",
    "\n",
    "# FIXED: Smaller batch size for stability\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4923a393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Attempting to load your fine-tuned model...\n",
      "üìÅ Found fine-tuned model. Analyzing its architecture...\n"
     ]
    }
   ],
   "source": [
    "# ====================== SMART MODEL LOADING ======================\n",
    "from models.resnet_1d import ResNet1D\n",
    "from torch.serialization import safe_globals\n",
    "\n",
    "print(\"üîß Attempting to load your fine-tuned model...\")\n",
    "\n",
    "# First, try to load your fine-tuned model and reverse-engineer its config\n",
    "finetuned_path = \"checkpoints/best_stage1_model.pt\"\n",
    "if os.path.exists(finetuned_path):\n",
    "    print(\"üìÅ Found fine-tuned model. Analyzing its architecture...\")\n",
    "    \n",
    "    # Load the fine-tuned state dict\n",
    "    finetuned_state = torch.load(finetuned_path, map_location=\"cpu\")\n",
    "    \n",
    "    # Analyze the architecture from the saved weights\n",
    "    def get_config_from_state_dict(state_dict):\n",
    "        \"\"\"Reverse engineer model config from state dict\"\"\"\n",
    "        config = {\n",
    "            'in_channels': 22,  # We know this\n",
    "            'use_age': 'fc',    # We know this\n",
    "            'out_dims': 3,      # We know this\n",
    "        }\n",
    "        \n",
    "        # Try to determine other parameters from the state dict shapes\n",
    "        if 'conv_stage1.1.conv1.weight' in state_dict:\n",
    "            kernel_size = state_dict['conv_stage1.1.conv1.weight'].shape[2]\n",
    "            config['kernel_size'] = kernel_size\n",
    "            print(f\"üîç Detected kernel_size: {kernel_size}\")\n",
    "        \n",
    "        # Check if we have any conv layer to determine base_filters\n",
    "        for key in state_dict.keys():\n",
    "            if 'conv_stage1.0.conv1.weight' in key:\n",
    "                base_filters = state_dict[key].shape[0]\n",
    "                config['base_filters'] = base_filters\n",
    "                print(f\"üîç Detected base_filters: {base_filters}\")\n",
    "                break\n",
    "        \n",
    "        # Check final FC layer size to determine hidden sizes\n",
    "        if 'fc_stage.2.weight' in state_dict:\n",
    "            final_fc_input = state_dict['fc_stage.2.weight'].shape[1]\n",
    "            print(f\"üîç Final FC input size: {final_fc_input}\")\n",
    "            \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b62c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detected kernel_size: 1\n",
      "üîç Final FC input size: 512\n",
      "üîç Inferred config: {'in_channels': 22, 'use_age': 'fc', 'out_dims': 3, 'kernel_size': 1}\n",
      "\n",
      "üß™ Trying configuration 1: {'in_channels': 22, 'use_age': 'fc', 'out_dims': 3, 'kernel_size': 9, 'base_filters': 64, 'block_nums': [2, 2, 2, 2], 'pool_sizes': [2, 2, 2, 2], 'pool_strides': [2, 2, 2, 2], 'fc_hidden_sizes': [512, 256, 128]}\n",
      "‚ùå Config 1 failed with error: ResNet1D.__init__() missing 5 required positional arguments: 'block', 'conv_layers', 'seq_length', 'base_channels', and 'fc_stages'\n",
      "\n",
      "üß™ Trying configuration 2: {'in_channels': 22, 'use_age': 'fc', 'out_dims': 3, 'kernel_size': 9, 'base_filters': 32, 'block_nums': [2, 2, 2, 2], 'pool_sizes': [2, 2, 2, 2], 'pool_strides': [2, 2, 2, 2], 'fc_hidden_sizes': [256, 128]}\n",
      "‚ùå Config 2 failed with error: ResNet1D.__init__() missing 5 required positional arguments: 'block', 'conv_layers', 'seq_length', 'base_channels', and 'fc_stages'\n",
      "\n",
      "üß™ Trying configuration 3: {'in_channels': 22, 'use_age': 'fc', 'out_dims': 3, 'kernel_size': 9, 'base_filters': 32, 'block_nums': [1, 1, 1, 1], 'pool_sizes': [2, 2, 2, 2], 'pool_strides': [2, 2, 2, 2], 'fc_hidden_sizes': [256, 128]}\n",
      "‚ùå Config 3 failed with error: ResNet1D.__init__() missing 5 required positional arguments: 'block', 'conv_layers', 'seq_length', 'base_channels', and 'fc_stages'\n",
      "‚ùå Could not find matching configuration. Let's try a different approach...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sruthi\\AppData\\Local\\Temp\\ipykernel_25616\\1937226449.py:80: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.multiarray.\n",
      "  with safe_globals({\"scalar\": np.core.multiarray.scalar}):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Using original config as fallback: {'dataset_path': 'local/dataset/02_Curated_Data_220419/', 'file_format': 'feather', 'crop_multiple': 4, 'test_crop_multiple': 8, 'crop_timing_analysis': False, 'load_event': False, 'seq_length': 2000, 'latency': 2000, 'signal_length_limit': 10000000, 'EKG': 'O', 'photic': 'O', 'input_norm': 'dataset', 'awgn': 0, 'awgn_age': 0, 'mgn': 0, 'task': 'dementia', 'run_mode': 'train', 'seed': 0, 'base_lr': 0.00046936536527944847, 'search_lr': False, 'search_multiplier': 1.0, 'lr_scheduler_type': 'cosine_decay_with_warmup_half', 'warmup_ratio': 0.05, 'warmup_min': 3000, 'total_samples': 100000000.0, 'criterion': 'multi-bce', 'weight_decay': 0.04394746639552375, 'mixup': 0.2, 'num_history': 500, 'save_model': True, 'use_wandb': True, 'draw_result': True, 'watch_model': False, 'ddp': False, 'project': 'caueeg-task2-ablation', '_target_': 'models.resnet_1d.ResNet1D', 'model': '1D-ResNet-18', 'in_channels': 22, 'out_dims': 3, 'block': 'basic', 'conv_layers': [2, 2, 2, 2], 'base_channels': 64, 'use_age': 'fc', 'fc_stages': 3, 'dropout': 0.3, 'activation': 'gelu', 'minibatch': 512, 'cwd': '/home/imkbsz/workspace/eeg_analysis', 'device': device(type='cuda'), 'dataset_name': 'CAUEEG dataset', 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'], 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      "), 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      "), 'task_name': 'CAUEEG-Dementia benchmark', 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.', 'class_label_to_name': ['Normal', 'MCI', 'Dementia'], 'class_name_to_label': {'Normal': 0, 'MCI': 1, 'Dementia': 2}, 'multi_batch_size': 64, 'age_mean': tensor([71.1417]), 'age_std': tensor([9.7840]), 'signal_mean': tensor([[[ 0.1507],\n",
      "         [ 0.0541],\n",
      "         [-0.0413],\n",
      "         [ 0.0160],\n",
      "         [-0.0541],\n",
      "         [ 0.1908],\n",
      "         [-0.0025],\n",
      "         [-0.0211],\n",
      "         [ 0.0069],\n",
      "         [ 0.0494],\n",
      "         [ 0.0051],\n",
      "         [-0.0056],\n",
      "         [-0.0354],\n",
      "         [ 0.0505],\n",
      "         [-0.0412],\n",
      "         [ 0.1035],\n",
      "         [ 0.0074],\n",
      "         [-0.0325],\n",
      "         [-0.0373],\n",
      "         [-0.0025],\n",
      "         [-0.0071]]]), 'signal_std': tensor([[[45.0080],\n",
      "         [20.2708],\n",
      "         [11.7008],\n",
      "         [11.5876],\n",
      "         [15.2168],\n",
      "         [47.7619],\n",
      "         [19.8388],\n",
      "         [10.5537],\n",
      "         [11.6707],\n",
      "         [15.9614],\n",
      "         [20.6152],\n",
      "         [14.4362],\n",
      "         [13.6445],\n",
      "         [21.9794],\n",
      "         [16.9491],\n",
      "         [14.6477],\n",
      "         [19.7299],\n",
      "         [11.4548],\n",
      "         [11.6362],\n",
      "         [94.2795],\n",
      "         [68.4567]]]), 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417]),std=tensor([9.7840]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.1507,  0.0541, -0.0413,  0.0160, -0.0541,  0.1908, -0.0025, -0.0211,\n",
      "           0.0069,  0.0494,  0.0051, -0.0056, -0.0354,  0.0505, -0.0412,  0.1035,\n",
      "           0.0074, -0.0325, -0.0373, -0.0025, -0.0071]),std=tensor([45.0080, 20.2708, 11.7008, 11.5876, 15.2168, 47.7619, 19.8388, 10.5537,\n",
      "          11.6707, 15.9614, 20.6152, 14.4362, 13.6445, 21.9794, 16.9491, 14.6477,\n",
      "          19.7299, 11.4548, 11.6362, 94.2795, 68.4567]),eps=1e-08)\n",
      "), 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417]),std=tensor([9.7840]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.1507,  0.0541, -0.0413,  0.0160, -0.0541,  0.1908, -0.0025, -0.0211,\n",
      "           0.0069,  0.0494,  0.0051, -0.0056, -0.0354,  0.0505, -0.0412,  0.1035,\n",
      "           0.0074, -0.0325, -0.0373, -0.0025, -0.0071]),std=tensor([45.0080, 20.2708, 11.7008, 11.5876, 15.2168, 47.7619, 19.8388, 10.5537,\n",
      "          11.6707, 15.9614, 20.6152, 14.4362, 13.6445, 21.9794, 16.9491, 14.6477,\n",
      "          19.7299, 11.4548, 11.6362, 94.2795, 68.4567]),eps=1e-08)\n",
      "), 'output_length': 8, 'num_params': 11394051, 'iterations': 195312, 'warmup_steps': 9766}\n",
      "‚ö†Ô∏è  Loaded backbone only. Will need to retrain classifier (should be quick!)\n"
     ]
    }
   ],
   "source": [
    "# Get config from your saved model\n",
    "inferred_config = get_config_from_state_dict(finetuned_state)\n",
    "print(f\"üîç Inferred config: {inferred_config}\")\n",
    "\n",
    "# Try different common configurations that might match\n",
    "possible_configs = [\n",
    "    # Config 1: Default ResNet-like\n",
    "    {\n",
    "        'in_channels': 22,\n",
    "        'use_age': 'fc',\n",
    "        'out_dims': 3,\n",
    "        'kernel_size': 9,\n",
    "        'base_filters': 64,\n",
    "        'block_nums': [2, 2, 2, 2],\n",
    "        'pool_sizes': [2, 2, 2, 2],\n",
    "        'pool_strides': [2, 2, 2, 2],\n",
    "        'fc_hidden_sizes': [512, 256, 128]\n",
    "    },\n",
    "    # Config 2: Smaller model\n",
    "    {\n",
    "        'in_channels': 22,\n",
    "        'use_age': 'fc',\n",
    "        'out_dims': 3,\n",
    "        'kernel_size': 9,\n",
    "        'base_filters': 32,\n",
    "        'block_nums': [2, 2, 2, 2],\n",
    "        'pool_sizes': [2, 2, 2, 2],\n",
    "        'pool_strides': [2, 2, 2, 2],\n",
    "        'fc_hidden_sizes': [256, 128]\n",
    "    },\n",
    "    # Config 3: Based on your error messages - seems like smaller model\n",
    "    {\n",
    "        'in_channels': 22,\n",
    "        'use_age': 'fc',\n",
    "        'out_dims': 3,\n",
    "        'kernel_size': 9,\n",
    "        'base_filters': 32,\n",
    "        'block_nums': [1, 1, 1, 1],\n",
    "        'pool_sizes': [2, 2, 2, 2],\n",
    "        'pool_strides': [2, 2, 2, 2],\n",
    "        'fc_hidden_sizes': [256, 128]\n",
    "    }\n",
    "]\n",
    "\n",
    "model = None\n",
    "successful_config = None\n",
    "\n",
    "# Try each configuration\n",
    "for i, config in enumerate(possible_configs):\n",
    "    print(f\"\\nüß™ Trying configuration {i + 1}: {config}\")\n",
    "    try:\n",
    "        test_model = ResNet1D(**config)\n",
    "        test_model.to(device)\n",
    "\n",
    "        # Try to load the weights\n",
    "        missing_keys, unexpected_keys = test_model.load_state_dict(finetuned_state, strict=False)\n",
    "\n",
    "        # Check if loading was successful (ignore batch norm stats)\n",
    "        if len(missing_keys) == 0 or all(\n",
    "            'running_mean' in key or 'running_var' in key or 'num_batches_tracked' in key\n",
    "            for key in missing_keys\n",
    "        ):\n",
    "            print(\"‚úÖ SUCCESS! Found matching configuration!\")\n",
    "            model = test_model\n",
    "            successful_config = config\n",
    "            break\n",
    "        else:\n",
    "            print(f\"‚ùå Config {i + 1} failed: {len(missing_keys)} missing keys\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Config {i + 1} failed with error: {e}\")\n",
    "        continue\n",
    "\n",
    "if model is None:\n",
    "    print(\"‚ùå Could not find matching configuration. Let's try a different approach...\")\n",
    "\n",
    "    # Load original checkpoint for reference\n",
    "    checkpoint_path = \"checkpoints/checkpoint.pt\"\n",
    "    try:\n",
    "        with safe_globals({\"scalar\": np.core.multiarray.scalar}):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "        # Use original config but modify for your needs\n",
    "        model_config = checkpoint[\"config\"].copy()\n",
    "        model_config[\"in_channels\"] = 22\n",
    "        model_config[\"use_age\"] = \"fc\"\n",
    "        model_config[\"out_dims\"] = 3\n",
    "\n",
    "        print(f\"üìã Using original config as fallback: {model_config}\")\n",
    "        model = ResNet1D(**model_config)\n",
    "        model.to(device)\n",
    "\n",
    "        # Load only backbone weights\n",
    "        original_state = checkpoint[\"model_state\"]\n",
    "        filtered_state = {k: v for k, v in original_state.items() if not k.startswith(\"fc_stage\")}\n",
    "        model.load_state_dict(filtered_state, strict=False)\n",
    "\n",
    "        print(\"‚ö†Ô∏è  Loaded backbone only. Will need to retrain classifier (should be quick!)\")\n",
    "        successful_config = model_config\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fallback also failed: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "else:\n",
    "    print(f\"üéâ Successfully loaded your fine-tuned model!\")\n",
    "    print(f\"‚úÖ Configuration used: {successful_config}\")\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_eeg, sample_age, sample_label = next(iter(test_loader))\n",
    "        sample_eeg = sample_eeg.to(device)\n",
    "        sample_age = sample_age.to(device).unsqueeze(1)\n",
    "\n",
    "        output = model(sample_eeg, sample_age)\n",
    "        print(f\"‚úÖ Model test successful! Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009dec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluating loaded model...\n"
     ]
    }
   ],
   "source": [
    "# ====================== Training Functions ======================\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for eeg, age, label in train_loader:\n",
    "        eeg, age, label = eeg.to(device), age.to(device).unsqueeze(1), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(eeg, age)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "\n",
    "    return total_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for eeg, age, label in test_loader:\n",
    "            eeg, age, label = eeg.to(device), age.to(device).unsqueeze(1), label.to(device)\n",
    "\n",
    "            output = model(eeg, age)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += label.size(0)\n",
    "            correct += predicted.eq(label).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(test_loader), 100. * correct / total, all_preds, all_labels\n",
    "\n",
    "# ====================== Evaluation of Loaded Model ======================\n",
    "print(\"\\nüìä Evaluating loaded model...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85dba374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluating loaded model...\n",
      "Current Model Test Accuracy: 33.33%\n",
      "Model accuracy (33.33%) is below threshold. Starting training...\n"
     ]
    }
   ],
   "source": [
    "# ====================== Evaluation of Loaded Model ======================\n",
    "print(\"\\nüìä Evaluating loaded model...\")\n",
    "\n",
    "# Handle class imbalance\n",
    "class_counts = np.bincount([s[2] for s in train_samples])\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Evaluate current model performance\n",
    "_, test_acc, test_preds, test_labels = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Current Model Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# If accuracy is good (>70%), skip training\n",
    "if test_acc > 70:\n",
    "    print(\"‚úÖ Model already has good performance! Skipping training.\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=[\"HC\", \"MCI\", \"AD\"]))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['HC', 'MCI', 'AD'],\n",
    "                yticklabels=['HC', 'MCI', 'AD'])\n",
    "    plt.title(f'Confusion Matrix - Test Accuracy: {test_acc:.2f}%')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the properly loaded model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': model_config,\n",
    "        'stats': stats,\n",
    "        'test_accuracy': test_acc\n",
    "    }, \"checkpoints/final_loaded_model.pt\")\n",
    "    print(\"‚úÖ Model saved to checkpoints/final_loaded_model.pt\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Model accuracy ({test_acc:.2f}%) is below threshold. Starting training...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d47a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîí Stage 1: Training classifier only\n",
      "Epoch  1: Train Loss=0.9671, Train Acc=58.33%, Val Loss=1.3050, Val Acc=65.94%\n",
      "üíæ New best model saved! Val Acc: 65.94%\n",
      "Epoch  2: Train Loss=0.9138, Train Acc=62.86%, Val Loss=1.4160, Val Acc=61.59%\n",
      "Epoch  3: Train Loss=0.9336, Train Acc=58.15%, Val Loss=0.7913, Val Acc=66.67%\n",
      "üíæ New best model saved! Val Acc: 66.67%\n",
      "Epoch  4: Train Loss=0.8942, Train Acc=61.78%, Val Loss=0.6358, Val Acc=73.19%\n",
      "üíæ New best model saved! Val Acc: 73.19%\n",
      "Epoch  5: Train Loss=0.8290, Train Acc=67.21%, Val Loss=0.6985, Val Acc=71.74%\n",
      "Epoch  6: Train Loss=0.8548, Train Acc=61.05%, Val Loss=0.7055, Val Acc=67.39%\n",
      "Epoch  7: Train Loss=0.8441, Train Acc=65.76%, Val Loss=0.6201, Val Acc=75.36%\n",
      "üíæ New best model saved! Val Acc: 75.36%\n",
      "Epoch  8: Train Loss=0.8197, Train Acc=64.67%, Val Loss=0.6688, Val Acc=71.74%\n",
      "Epoch  9: Train Loss=0.8510, Train Acc=65.58%, Val Loss=1.1312, Val Acc=69.57%\n",
      "Epoch 10: Train Loss=0.8320, Train Acc=64.49%, Val Loss=1.0688, Val Acc=65.22%\n",
      "\n",
      "‚úÖ Training completed! Best accuracy: 75.36%\n"
     ]
    }
   ],
   "source": [
    "# Continue with training if needed\n",
    "print(\"\\nüîí Stage 1: Training classifier only\")\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = name.startswith(\"fc_stage\")\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "best_val_acc = test_acc  # Start with current accuracy\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(10):  # Reduced epochs since we're starting from a good point\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
    "          f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'config': model_config,\n",
    "            'stats': stats,\n",
    "            'test_accuracy': val_acc\n",
    "        }, \"checkpoints/best_retrained_model.pt\")\n",
    "        print(f\"üíæ New best model saved! Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed! Best accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe22b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† EEG File: 1_00001.csv\n",
      "‚úÖ Predicted Label: MCI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_single_file(file_path, true_age, true_label, model, stats):\n",
    "    \"\"\"\n",
    "    Run inference on a single EEG file.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    eeg_tensor = preprocess_eeg(file_path, stats=stats).unsqueeze(0).to(device)  # [1, 22, 500]\n",
    "    age_tensor = torch.tensor([(true_age - stats['age_mean']) / stats['age_std']], dtype=torch.float32).unsqueeze(1).to(device)  # [1, 1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(eeg_tensor, age_tensor)\n",
    "        predicted_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    class_names = ['HC', 'MCI', 'AD']\n",
    "    print(f\"\\nüß† EEG File: {os.path.basename(file_path)}\")\n",
    "    print(f\"‚úÖ Predicted Label: {class_names[predicted_class]}\")\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# üîç Predict from one EEG file\n",
    "# Example file path and metadata ‚Äî replace with actual values\n",
    "test_file_path = \"data/balanced_subset/1_00001.csv\"\n",
    "\n",
    "\n",
    "predict_single_file(test_file_path, true_age, true_label, model, stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f335b570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final Evaluation\n",
      "Final Test Accuracy: 76.81%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.85      0.85      0.85        46\n",
      "         MCI       0.68      0.70      0.69        46\n",
      "          AD       0.78      0.76      0.77        46\n",
      "\n",
      "    accuracy                           0.77       138\n",
      "   macro avg       0.77      0.77      0.77       138\n",
      "weighted avg       0.77      0.77      0.77       138\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================== Final Evaluation ======================\n",
    "print(\"\\nüìä Final Evaluation\")\n",
    "model.load_state_dict(torch.load(\"checkpoints/best_final_model.pt\"))\n",
    "\n",
    "_, test_acc, test_preds, test_labels = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=[\"HC\", \"MCI\", \"AD\"]))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['HC', 'MCI', 'AD'],\n",
    "            yticklabels=['HC', 'MCI', 'AD'])\n",
    "plt.title(f'Confusion Matrix - Test Accuracy: {test_acc:.2f}%')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
